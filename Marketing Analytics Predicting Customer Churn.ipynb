{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TELCO CUSTOMER CHURN BUSINESS CASE\n",
    "\n",
    "# Exploratory analysis w/ pandas & seaborn\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "telcoc.value_counts\n",
    "print(telco.groupby(['Churn']).mean())\n",
    "print(telco.groupby(['Churn']).std())\n",
    "\n",
    "# Count the number of churners and non-churners by State\n",
    "print(telco.groupby('State')['Churn'].value_counts())\n",
    "\n",
    "# Distribution visualization\n",
    "import matplolib.pyplot as plt\n",
    "import seaborn as sns #seaborn is built on top of matplotlib\n",
    "\n",
    "# Create the distribution plot\n",
    "sns.distplot(telco['Account_length']) #check the distribution ie normal\n",
    "plt.show()\n",
    "\n",
    "# Create the box plot\n",
    "sns.boxplot(x = 'Churn',\n",
    "            y = 'CustServ_Calls',\n",
    "            data = telco,\n",
    "            sym = \"\", #remove the outliers\n",
    "            hue = 'Intl_Plan')#hue: 3rd variable to visualize whether or not having \n",
    "#a voice mail plan affects the number of customer service calls or churn.\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing including feature scaling > standardization \n",
    "\n",
    "# standardization centers the distribution around the mean\n",
    "# calculates the number of std away from the mean each point is\n",
    "\n",
    "\n",
    "# ENCODING BINARY FEATURES\n",
    "telco.info() #transform objects into binary\n",
    "\n",
    "# Replace 'no' with 0 and 'yes' with 1 in 'Vmail_Plan'\n",
    "telco['Vmail_Plan'] = telco['Vmail_Plan'].replace(('yes', 'no'), (1, 0))\n",
    "\n",
    "# Replace 'no' with 0 and 'yes' with 1 in 'Churn'\n",
    "telco['Churn'] = telco['Churn'].replace(('yes', 'no'), (1, 0))\n",
    "\n",
    "# Print the results to verify\n",
    "print(telco['Vmail_Plan'].head())\n",
    "print(telco['Churn'].head())\n",
    "\n",
    "\n",
    "# DUMMIES\n",
    "# Perform one hot encoding on 'State'\n",
    "telco_state = pd.get_dummies(telco.State)\n",
    "\n",
    "# Print the head of telco_state\n",
    "print(telco_state.head())\n",
    "\n",
    "\n",
    "# FEATURE SCALING\n",
    "# Import StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Scale telco using StandardScaler\n",
    "telco_scaled = StandardScaler().fit_transform(telco)\n",
    "telco_scaled_df = pd.DataFrame(telco_scaled, columns=[\"Intl_Calls\", \"Night_Mins\"]) # Add column names back for readability\n",
    "print(telco_scaled_df.describe())\n",
    "\n",
    "# FEATURES ENGINEERING\n",
    "# Drop the unnecessary features\n",
    "telco = telco.drop(['Area_Code', 'Phone'], axis=1)\n",
    "\n",
    "# Engineering a new column\n",
    "telco['Avg_Night_Calls'] = telco.Night_Mins / telco.Night_Calls\n",
    "print(telco.Avg_Night_Calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dirty models\n",
    "\n",
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression() # Instantiate the classifier\n",
    "clf.fit(telco[features], telco['Churn']) # Train the classifier\n",
    "print(clf.predict(new_customer)) #print the prediction\n",
    "\n",
    "# Decision Tree Classifier\n",
    "from sklearn.linear_model import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier() # Instantiate the classifier\n",
    "clf.fit(telco[features], telco['Churn']) # Train the classifier\n",
    "print(clf.predict(new_customer)) #print the prediction\n",
    "\n",
    "# Support Vector Classifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC() #instantiate the model\n",
    "svc.fit(telco[features], telco['Churn']) #train the model\n",
    "print(svc.predict(new_customer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_curve \n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score \n",
    "\n",
    "X = telco.drop('Churn', axis=1) # drop the target variable\n",
    "y = telco['Churn'] # Create target variable\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3) # Create training and testing sets\n",
    "\n",
    "clf = RandomForestClassifier() #instantiate the model\n",
    "clf.fit(X_train,y_train) #train the model\n",
    "\n",
    "print(clf.score(X_test, y_test)) # Compute accuracy\n",
    "\n",
    "# <script.py> output:\n",
    "#  0.934\n",
    "\n",
    "# Evaluating Model Performance\n",
    "\n",
    "# accuracy might not be that useful with unbalanced classes\n",
    "# precision: true positives / (true positives + false positives)\n",
    "# recall: true positives / (true positives + false negatives) =synonymous with sensitivity\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred)) \n",
    "# <script.py> output:\n",
    "#[[842  13]\n",
    "# [ 53  92]]\n",
    "\n",
    "print(precision_score(y_test, y_pred))\n",
    "# <script.py> output:\n",
    "# 0.9176470588235294\n",
    "\n",
    "print(recall_score(y_test, y_pred))\n",
    "# <script.py> output:\n",
    "# 0.7513761467889908\n",
    "\n",
    "y_pred_prob = clf.predict_proba(X_test)[:, 1] # Generate the probabilities\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob) # Calculate the roc metrics\n",
    "\n",
    "plt.plot(fpr,tpr) #plot\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.plot([0, 1], [0, 1], \"k--\")\n",
    "plt.show()\n",
    "\n",
    "print(roc_auc_score(y_test, y_pred_prob)) # Print the Area Under the Curve AUC\n",
    "# <script.py> output:\n",
    "#    0.8938011695906432\n",
    "\n",
    "print(f1_score(y_test, y_pred))\n",
    "# <script.py> output:\n",
    "#    0.723404255319149"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model tuning\n",
    "\n",
    "# Hyper parameters\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_grid = {'max_features': ['auto', 'sqrt', 'log2']} # Create the hyperparameter grid\n",
    "\n",
    "grid_search = GridSearchCV(clf, param_grid) # Call GridSearchCV\n",
    "grid_search.fit(X, y) # Fit the model\n",
    "\n",
    "print(grid_search.best_params_) # Print the optimal parameters\n",
    "#{'max_features': 'log2'}\n",
    "\n",
    "param_dist = {\"max_depth\": [3, None], # Create the hyperparameter grid\n",
    "              \"max_features\": randint(1, 11),\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "random_search = RandomizedSearchCV(clf, param_dist)\n",
    "random_search.fit(X,y)\n",
    "\n",
    "print(random_search.best_params_) \n",
    "#<script.py> output:\n",
    "#    {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': 10}\n",
    "\n",
    "# Feature importances\n",
    "\n",
    "# > Which features are important to predict churn? Which ones can be removed from the model?\n",
    "\n",
    "importances = clf.feature_importances_ # Calculate feature importances\n",
    "\n",
    "plt.barh(range(X.shape[1]), importances) #horizontal bar plot\n",
    "plt.show()\n",
    "\n",
    "sorted_index = np.argsort(importances) # Sort importances\n",
    "labels = X.columns[sorted_index]\n",
    "\n",
    "plt.clf() # Clear current plot\n",
    "plt.barh(range(X.shape[1]), importances[sorted_index], tick_label=labels) # new plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding new features\n",
    "\n",
    "# 6 new features have been added to the telco DataFrame:\n",
    "\n",
    "# Region_Code\n",
    "# Cost_Call\n",
    "# Total_Charge\n",
    "# Total_Minutes\n",
    "# Total_Calls\n",
    "# Min_Call\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "clf = RandomForestClassifier() #instantiate the model\n",
    "clf.fit(X_train,y_train) #train the model\n",
    "\n",
    "print(clf.score(X_test, y_test)) # Compute accuracy\n",
    "# <script.py> output:\n",
    "#  0.954\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(f1_score(y_test, y_pred))\n",
    "# <script.py> output:\n",
    "#  0.8130081300813008"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
